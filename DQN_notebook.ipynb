{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, List, Tuple\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import gym\n",
    "import envs\n",
    "from datetime import datetime\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "from pyfmi import load_fmu\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.offline as pyo\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"A simple numpy replay buffer.\"\"\"\n",
    "\n",
    "    def __init__(self, obs_dim: int, size: int, batch_size: int = 32):\n",
    "        self.obs_dim = obs_dim\n",
    "        self.obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "        self.next_obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "        self.acts_buf = np.zeros([size], dtype=np.float32)\n",
    "        self.rews_buf = np.zeros([size], dtype=np.float32)\n",
    "        self.done_buf = np.zeros(size, dtype=np.float32)\n",
    "        self.max_size, self.batch_size = size, batch_size\n",
    "        self.ptr, self.size, = 0, 0\n",
    "\n",
    "    def store(\n",
    "        self,\n",
    "        obs: np.ndarray,\n",
    "        act: np.ndarray, \n",
    "        rew: float, \n",
    "        next_obs: np.ndarray, \n",
    "        done: bool,\n",
    "    ):\n",
    "        self.obs_buf[self.ptr] = obs.reshape(self.obs_buf[self.ptr].shape)\n",
    "        self.next_obs_buf[self.ptr] = next_obs.reshape(self.obs_buf[self.ptr].shape)\n",
    "        self.acts_buf[self.ptr] = act\n",
    "        self.rews_buf[self.ptr] = rew\n",
    "        self.done_buf[self.ptr] = done\n",
    "        self.ptr = (self.ptr + 1) % self.max_size\n",
    "        self.size = min(self.size + 1, self.max_size)\n",
    "\n",
    "    def sample_batch(self) -> Dict[str, np.ndarray]:\n",
    "        idxs = np.random.choice(self.size, size=self.batch_size, replace=False)\n",
    "        return dict(obs=self.obs_buf[idxs],\n",
    "                    next_obs=self.next_obs_buf[idxs],\n",
    "                    acts=self.acts_buf[idxs],\n",
    "                    rews=self.rews_buf[idxs],\n",
    "                    done=self.done_buf[idxs])\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, in_dim: int, out_dim: int):\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        super(Network, self).__init__()\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(in_dim, 128), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(128, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward method implementation.\"\"\"\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    \"\"\"DQN Agent interacting with environment.\n",
    "    \n",
    "    Attribute:\n",
    "        env : (Environment) custom Environment to interact with TRNSYS\n",
    "        memory (ReplayBuffer): replay memory to store transitions\n",
    "        batch_size (int): batch size for sampling\n",
    "        epsilon (float): parameter for epsilon greedy policy\n",
    "        epsilon_decay (float): step size to decrease epsilon\n",
    "        max_epsilon (float): max value of epsilon\n",
    "        min_epsilon (float): min value of epsilon\n",
    "        target_update (int): period for target model's hard update\n",
    "        gamma (float): discount factor\n",
    "        dqn (Network): model to train and select actions\n",
    "        dqn_target (Network): target model to update\n",
    "        optimizer (torch.optim): optimizer for training dqn\n",
    "        transition (list): transition information including \n",
    "                           state, action, reward, next_state, done\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        env: gym.Env,\n",
    "        memory_size: int,\n",
    "        batch_size: int,\n",
    "        target_update: int,\n",
    "        epsilon_decay: float,\n",
    "        max_epsilon: float = 1.0,\n",
    "        min_epsilon: float = 0.1,\n",
    "        gamma: float = 0.99,\n",
    "    ):\n",
    "        \"\"\"Initialization.\n",
    "        \n",
    "        Args:\n",
    "            env (gym.Env): custom Environment to interact with TRNSYS\n",
    "            memory_size (int): length of memory\n",
    "            batch_size (int): batch size for sampling\n",
    "            target_update (int): period for target model's hard update\n",
    "            epsilon_decay (float): step size to decrease epsilon\n",
    "            lr (float): learning rate\n",
    "            max_epsilon (float): max value of epsilon\n",
    "            min_epsilon (float): min value of epsilon\n",
    "            gamma (float): discount factor\n",
    "        \"\"\"\n",
    "        ## dimensions for the network\n",
    "        obs_dim = env.observation_dim\n",
    "        action_dim = env.action_dim\n",
    "        \n",
    "        self.env = env\n",
    "        self.memory = ReplayBuffer(obs_dim, memory_size, batch_size)\n",
    "        self.batch_size = batch_size\n",
    "        self.epsilon = max_epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.max_epsilon = max_epsilon\n",
    "        self.min_epsilon = min_epsilon\n",
    "        self.target_update = target_update\n",
    "        self.gamma = gamma\n",
    "        \n",
    "        # device: cpu / gpu\n",
    "        self.device = torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        )\n",
    "\n",
    "\n",
    "        print(self.device)\n",
    "\n",
    "        # networks: dqn, dqn_target\n",
    "        self.dqn = Network(obs_dim, action_dim).to(self.device)\n",
    "        self.dqn_target = Network(obs_dim, action_dim).to(self.device)\n",
    "        self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
    "        self.dqn_target.eval()\n",
    "        \n",
    "        # optimizer\n",
    "        self.optimizer = optim.Adam(self.dqn.parameters())\n",
    "\n",
    "        # transition to store in memory\n",
    "        self.transition = list()\n",
    "        \n",
    "        # mode: train / test\n",
    "        self.is_test = False\n",
    "\n",
    "\n",
    "    def __getattribute__(self, attr):\n",
    "        return object.__getattribute__(self, attr)\n",
    "\n",
    "    def __setattr__(self, attr, value):\n",
    "        object.__setattr__(self, attr, value)\n",
    "\n",
    "        \n",
    "\n",
    "    def select_action(self, state: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Select an action from the input state.\"\"\"\n",
    "        # epsilon greedy policy\n",
    "        if self.epsilon > np.random.random():\n",
    "            selected_action = np.random.choice(self.env.action_dim,1)[0]\n",
    "        else:\n",
    "            selected_action = self.dqn(\n",
    "                torch.FloatTensor(state.T).to(self.device)\n",
    "            ).argmax()\n",
    "            selected_action = selected_action.detach().cpu().numpy()\n",
    "        \n",
    "        if not self.is_test:\n",
    "            self.transition = [state, selected_action]\n",
    "        \n",
    "        return selected_action\n",
    "\n",
    "    def step(self, action: np.ndarray) -> Tuple[np.ndarray, np.float64, bool]:\n",
    "        \"\"\"Take an action and return the response of the env.\"\"\"\n",
    "        next_state, reward, done, info = self.env.step(action)\n",
    "\n",
    "        if not self.is_test:\n",
    "            self.transition += [reward, next_state, done]\n",
    "            self.memory.store(*self.transition)\n",
    "    \n",
    "        return next_state, reward, done, info\n",
    "\n",
    "    def update_model(self) -> torch.Tensor:\n",
    "        \"\"\"Update the model by gradient descent.\"\"\"\n",
    "        samples = self.memory.sample_batch()\n",
    "\n",
    "        loss = self._compute_dqn_loss(samples)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return loss.item()\n",
    "        \n",
    "    def train(self,num_iterations= None, ):\n",
    "        \"\"\"Train the agent.\"\"\"\n",
    "        self.is_test = False\n",
    "        \n",
    "        state = self.env.reset()\n",
    "        \n",
    "        update_cnt = 0\n",
    "        epsilons = []\n",
    "        losses = []\n",
    "        tair = []\n",
    "        actions = []\n",
    "        pmv = []\n",
    "        qheat = []\n",
    "        rewards = []\n",
    "        occ = []\n",
    "\n",
    "        if num_iterations is None:\n",
    "            num_iterations=env.numsteps\n",
    "\n",
    "\n",
    "        for i in range(num_iterations):\n",
    "            action = self.select_action(state)\n",
    "            next_state, reward, done,info = self.step(action)\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                print(f\"Iteration{i}\")\n",
    "\n",
    "            ## keeping track of the value we've seen\n",
    "            rewards.append(reward)\n",
    "            actions.append(env.action_to_temp[action])\n",
    "            pmv.append(info['pmv'][0])\n",
    "            d = env.observation_to_dict(next_state)\n",
    "            tair.append(d[\"Tair\"][0])\n",
    "            qheat.append(d[\"Qheat\"][0])\n",
    "            occ.append(d[\"Occ\"][0])\n",
    "            \n",
    "\n",
    "\n",
    "            state = next_state\n",
    "\n",
    "            # if episode ends\n",
    "            if done:\n",
    "                state = self.env.reset()\n",
    "\n",
    "            # if training is ready\n",
    "            if len(self.memory) >= self.batch_size:\n",
    "                loss = self.update_model()\n",
    "                losses.append(loss)\n",
    "                update_cnt += 1\n",
    "                \n",
    "                # linearly decrease epsilon\n",
    "                self.epsilon = max(\n",
    "                    self.min_epsilon, self.epsilon - (\n",
    "                        self.max_epsilon - self.min_epsilon\n",
    "                    ) * self.epsilon_decay\n",
    "                )\n",
    "                epsilons.append(self.epsilon)\n",
    "                \n",
    "                # if hard update is needed\n",
    "                if update_cnt % self.target_update == 0:\n",
    "                    self._target_hard_update()\n",
    "\n",
    "\n",
    "        \n",
    "        ## getting current date for logging reasons\n",
    "        date = datetime.now()\n",
    "        temp = list([date.year,date.month,date.day,date.hour,date.minute])\n",
    "        temp = [str(x) for x in temp]\n",
    "        time = \"_\".join(temp)\n",
    "        RESULT_PATH = f\"./results/{str(date.year)}_{str(date.month)}_{str(date.day)}/results_{time}\"\n",
    "        os.makedirs(RESULT_PATH,exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "        plot_filename=f\"{RESULT_PATH}/results_{time}.html\"\n",
    "        self._plot(epsilons,losses,tair,actions,pmv,qheat,rewards,occ,plot_filename = plot_filename)\n",
    "\n",
    "        self.plot_pmv_percentages(pmv=np.array(pmv),savepath=RESULT_PATH)\n",
    "\n",
    "        ## padding losses and epsilons so that they fit into dataframe\n",
    "        len_difference = len(tair) - len(losses)\n",
    "        pad_losses = [0 for i in range(len_difference)]\n",
    "        pad_epsilon = [epsilons[0] for i in range(len_difference)]\n",
    "\n",
    "        losses = pad_losses + losses\n",
    "        epsilons = pad_epsilon + epsilons\n",
    "\n",
    "        data = pd.DataFrame({\"loss\": losses, \"epsilon\":epsilons, \"tair\":tair, \"action\":actions,\n",
    "        \"pmv\":pmv, \"qheat\":qheat,\"reward\":rewards, \"occ\":occ})\n",
    "\n",
    "        data.to_csv(f\"{RESULT_PATH}/experiments_results_{time}.csv\")\n",
    "\n",
    "        ## saving parameters of environment\n",
    "\n",
    "        f = open(f\"{RESULT_PATH}/env_params_{time}.json\",\"w\")\n",
    "        f.write(json.dumps(env.log_dict(),indent=True))\n",
    "        f.close()\n",
    "\n",
    "        self.save(directory=RESULT_PATH,filename=\"torch\")\n",
    "        \n",
    "\n",
    "                \n",
    "        #self.env.close()\n",
    "\n",
    "\n",
    "    def _plot(\n",
    "        self, \n",
    "        epsilons: List[float],\n",
    "        losses : List[float],\n",
    "        tair: List[float],\n",
    "        actions: List[float],\n",
    "        pmv : List[float],\n",
    "        qheat: List[float],\n",
    "        rewards: List[float],\n",
    "        occ : List[float],\n",
    "        plot_filename:str\n",
    "       ):\n",
    "\n",
    "        epsilons = np.array(epsilons)\n",
    "        losses = np.array(losses)\n",
    "        tair= np.array(tair)\n",
    "        actions = np.array(actions)\n",
    "        pmv = np.array(pmv)\n",
    "        qheat = np.array(qheat)\n",
    "        rewards = np.array(rewards)\n",
    "        occ = np.array(occ)\n",
    "\n",
    "\n",
    "        # Plotting the summary of simulation\n",
    "        fig = make_subplots(rows=8, cols=1, shared_xaxes=True, vertical_spacing=0.02,\n",
    "                            specs=[[{\"secondary_y\": False}], [{\"secondary_y\": False}], [{\"secondary_y\": False}],\n",
    "                                   [{\"secondary_y\": True}], [{\"secondary_y\": True}], [{\"secondary_y\": False}],\n",
    "                                   [{\"secondary_y\": True}], [{\"secondary_y\": True}]])\n",
    "        \n",
    "        iterations = len(tair)\n",
    "        t = np.linspace(0.0, iterations -1, iterations)\n",
    "        # Add traces\n",
    "        fig.add_trace(go.Scatter(name='Tair(state)', x=t, y=tair.flatten(), mode='lines', line=dict(width=1, color='cyan')),\n",
    "                      row=1, col=1)\n",
    "        #fig.add_trace(go.Scatter(name='Tair_avg', x=t, y=pd.Series(tair.flatten()).rolling(window=60).mean(), mode='lines',\n",
    "        #              line=dict(width=2, color='blue')), row=1, col=1)\n",
    "\n",
    "        fig.add_trace(go.Scatter(name='Tset(action)', x=t, y=actions.flatten(), mode='lines', line=dict(width=1, color='fuchsia')),\n",
    "                      row=2, col=1)\n",
    "        fig.add_trace(go.Scatter(name='Tset_avg', x=t, y=pd.Series(actions.flatten()).rolling(window=24).mean(), mode='lines',\n",
    "                      line=dict(width=2, color='purple')), row=2, col=1)\n",
    "\n",
    "        fig.add_trace(go.Scatter(name='Pmv', x=t, y=pmv.flatten(), mode='lines', line=dict(width=1, color='gold')),\n",
    "                      row=3, col=1)\n",
    "        #fig.add_trace(go.Scatter(name='Pmv_avg', x=t, y=pd.Series(pmv.flatten()).rolling(window=60).mean(), mode='lines',\n",
    "        #              line=dict(width=2, color='darkorange')), row=3, col=1)\n",
    "\n",
    "        fig.add_trace(go.Scatter(name='Heating', x=t, y=qheat.flatten(), mode='lines', line=dict(width=1, color='red')),\n",
    "                      row=4, col=1, secondary_y=False)\n",
    "        fig.add_trace(go.Scatter(name='Heating_cumulative', x=t, y=np.cumsum(qheat.flatten()), mode='lines',\n",
    "                      line=dict(width=2, color='darkred')), row=4, col=1, secondary_y=True)\n",
    "\n",
    "        fig.add_trace(go.Scatter(name='Reward', x=t, y=rewards.flatten(), mode='lines', line=dict(width=1, color='lime')),\n",
    "                      row=5, col=1, secondary_y=False)\n",
    "        fig.add_trace(go.Scatter(name='Reward_cum', x=t, y=np.cumsum(rewards.flatten()), mode='lines',\n",
    "                      line=dict(width=2, color='darkgreen')), row=5, col=1, secondary_y=True)\n",
    "\n",
    "        fig.add_trace(go.Scatter(name='Occupancy', x=t, y=occ.flatten(), mode='lines',\n",
    "                      line=dict(width=1, color='black')), row=6, col=1)\n",
    "        ## training part\n",
    "\n",
    "        fig.add_trace(go.Scatter(name='Epsilons', x=t, y=epsilons.flatten(), mode='lines',\n",
    "                      line=dict(width=1, color='blue')), row=7, col=1)\n",
    "        fig.add_trace(go.Scatter(name='Training Loss', x=t, y=losses.flatten(), mode='lines',\n",
    "                      line=dict(width=1, color='darkblue')), row=8, col=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Set x-axis title\n",
    "        fig.update_xaxes(title_text=\"Timestep (-)\", row=6, col=1)\n",
    "        # Set y-axes titles\n",
    "        fig.update_yaxes(title_text=\"<b>Tair</b> (°C)\", range=[10, 24], row=1, col=1)\n",
    "        fig.update_yaxes(title_text=\"<b>Tset</b> (°C)\", range=[14, 22], row=2, col=1)\n",
    "        fig.update_yaxes(title_text=\"<b>PMV</b> (-)\", row=3, col=1)\n",
    "        fig.update_yaxes(title_text=\"<b>Heat Power</b> (kJ/hr)\", row=4, col=1, secondary_y=False)\n",
    "        fig.update_yaxes(title_text=\"<b>Heat Energy</b> (kJ)\", row=4, col=1, secondary_y=True)\n",
    "        fig.update_yaxes(title_text=\"<b>Reward</b> (-)\", row=5, col=1, range=[-5, 5], secondary_y=False)\n",
    "        fig.update_yaxes(title_text=\"<b>Tot Reward</b> (-)\", row=5, col=1, secondary_y=True)\n",
    "        fig.update_yaxes(title_text=\"<b>Fraction</b> (-)\", row=6, col=1)\n",
    "        fig.update_yaxes(title_text=\"<b>Epsilon</b> (-)\", row=7, col=1)\n",
    "        fig.update_yaxes(title_text=\"<b>Loss</b> (-)\", row=8, col=1)\n",
    "\n",
    "\n",
    "        fig.update_xaxes(nticks=50)\n",
    "        fig.update_layout(template='plotly_white', font=dict(family=\"Courier New, monospace\", size=10),\n",
    "                          legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1, xanchor=\"right\", x=1))\n",
    "\n",
    "\n",
    "            \n",
    "        pyo.plot(fig, filename=plot_filename)\n",
    "        ## saving as image to\n",
    "\n",
    "        \n",
    "\n",
    "    def plot_pmv_percentages(self, pmv: np.ndarray, savepath:str):\n",
    "        \n",
    "        temp = pmv\n",
    "        intervals = []\n",
    "        \n",
    "        length = 8\n",
    "        lower= -2\n",
    "        step = 0.5\n",
    "        \n",
    "        ranges = np.zeros(length)\n",
    "        \n",
    "        for i in range(length):\n",
    "        \n",
    "            if i == 0:\n",
    "                ranges[i] = (temp < lower).sum()\n",
    "                interval = f\"[-inf,{lower}]\"\n",
    "                intervals.append(interval)\n",
    "        \n",
    "            elif i == 7:\n",
    "                upper = (i-1)*step + lower\n",
    "                ranges[i] = ( upper<= temp).sum()\n",
    "                interval = f\"[{upper},inf]\"\n",
    "                intervals.append(interval)\n",
    "        \n",
    "            else:\n",
    "                lower_1 = lower + (i-1)*step\n",
    "                upper_1 = lower + (i)*step\n",
    "                ranges[i] = (( lower_1 <= temp) &(temp < upper_1)).sum()\n",
    "                interval = f\"[{lower_1},{upper_1}]\"\n",
    "                intervals.append(interval)\n",
    "        \n",
    "        \n",
    "        ranges = ranges / ranges.sum()\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "        # assign data\n",
    "        data = pd.DataFrame({'intervals':intervals,\n",
    "                             'ranges': ranges\n",
    "                            })\n",
    "        \n",
    "        \n",
    "        # compute percentage of each format\n",
    "        percentage = []\n",
    "        for i in range(data.shape[0]):\n",
    "            pct = data.ranges[i] * 100\n",
    "            percentage.append(round(pct,2))\n",
    "        data['Percentage'] = percentage\n",
    "        \n",
    "    \n",
    "        f,a = plt.subplots(1,1, figsize=(15,7))\n",
    "        colors_list = ['darkred','coral', 'coral', 'seagreen', 'lime', 'seagreen','coral','darkred']\n",
    "    \n",
    "        graph = plt.bar(x= data.intervals,height= data.ranges, color = colors_list)\n",
    "    \n",
    "        plt.xlabel(\"PMV value interval\")\n",
    "        plt.ylabel(\"Percentage of hours in interval\")\n",
    "        plt.title(\"Number of hours the algorithm spent in different PMV intervals\")\n",
    "        \n",
    "        i = 0\n",
    "        for p in graph:\n",
    "            width = p.get_width()\n",
    "            height = p.get_height()\n",
    "            x, y = p.get_xy()\n",
    "            plt.text(x+width/2,\n",
    "                     y+height*1.01,\n",
    "                     str(data.Percentage[i])+'%',\n",
    "                     ha='center',\n",
    "                     weight='bold')\n",
    "            i+=1\n",
    "        plt.savefig(f\"{savepath}/PMV_categories.png\",dpi=400)\n",
    "\n",
    "                \n",
    "\n",
    "    def _compute_dqn_loss(self, samples: Dict[str, np.ndarray]) -> torch.Tensor:\n",
    "        \"\"\"Return dqn loss.\"\"\"\n",
    "        device = self.device  # for shortening the following lines\n",
    "        state = torch.FloatTensor(samples[\"obs\"]).to(device)\n",
    "        next_state = torch.FloatTensor(samples[\"next_obs\"]).to(device)\n",
    "        action = torch.LongTensor(samples[\"acts\"].reshape(-1, 1)).to(device)\n",
    "        reward = torch.FloatTensor(samples[\"rews\"].reshape(-1, 1)).to(device)\n",
    "        done = torch.FloatTensor(samples[\"done\"].reshape(-1, 1)).to(device)\n",
    "\n",
    "        # G_t   = r + gamma * v(s_{t+1})  if state != Terminal\n",
    "        #       = r                       otherwise\n",
    "        curr_q_value = self.dqn(state).gather(1, action)\n",
    "        next_q_value = self.dqn_target(\n",
    "            next_state\n",
    "        ).max(dim=1, keepdim=True)[0].detach()\n",
    "        mask = 1 - done\n",
    "        target = (reward + self.gamma * next_q_value * mask).to(self.device)\n",
    "\n",
    "        # calculate dqn loss\n",
    "        loss = F.smooth_l1_loss(curr_q_value, target)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def _target_hard_update(self):\n",
    "        \"\"\"Hard update: target <- local.\"\"\"\n",
    "        self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
    "\n",
    "\n",
    "    # Making a save method to save a trained model\n",
    "    def save(self, filename, directory):\n",
    "        torch.save(self.dqn.state_dict(), '%s/%s_dqn.pth' % (directory, filename))\n",
    "        torch.save(self.dqn_target.state_dict(), '%s/%s_dqn_target.pth' % (directory, filename))\n",
    "\n",
    "    # Making a load method to load a pre-trained model\n",
    "    def load(self, filename, directory):\n",
    "        self.dqn.load_state_dict(torch.load('%s/%s_dqn.pth' % (directory, filename)))\n",
    "        self.dqn_target.load_state_dict(torch.load('%s/%s_dqn_target.pth' % (directory, filename)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 777\n",
    "\n",
    "\n",
    "def seed_torch(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.backends.cudnn.enabled:\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "np.random.seed(seed)\n",
    "seed_torch(seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set environment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('EnergyPlusEnv-v0')\n",
    "env.seed(seed)\n",
    "\n",
    "env.beta =1 \n",
    "env.alpha = 1\n",
    "env.min_temp = 16\n",
    "env.max_temp = 21\n",
    "env.action_dim =200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('EnergyPlusEnv-v0')\n",
    "env.seed(seed)\n",
    "\n",
    "env.beta =1 \n",
    "env.alpha = 1\n",
    "env.min_temp = 16\n",
    "env.max_temp = 21\n",
    "env.action_dim =200\n",
    "\n",
    "env.modelname = 'CELLS_v1.fmu'\n",
    "env.simulation_path = r'C:\\Users\\Harold\\Desktop\\ENAC-Semester-Project\\DIET_Controller\\custom_gym\\Eplus_simulation'\n",
    "env.param_list = ['Tair', 'RH', 'Tmrt', 'Tout', 'Qheat', 'Occ']\n",
    "\n",
    "env.days = 151,  \n",
    "env.hours = 24,  \n",
    "env.minutes = 60,\n",
    "env.seconds = 60,\n",
    "env.ep_timestep = 6\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "memory_size = 1000\n",
    "batch_size = 32\n",
    "target_update = 100\n",
    "epsilon_decay = 1 / 2000\n",
    "\n",
    "agent = DQNAgent(env,memory_size,batch_size,target_update,epsilon_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration0\n",
      "Iteration100\n",
      "Iteration200\n",
      "Iteration300\n",
      "Iteration400\n",
      "Iteration500\n",
      "Iteration600\n",
      "Iteration700\n",
      "Iteration800\n",
      "Iteration900\n",
      "Iteration1000\n",
      "Iteration1100\n",
      "Iteration1200\n",
      "Iteration1300\n",
      "Iteration1400\n",
      "Iteration1500\n",
      "Iteration1600\n",
      "Iteration1700\n",
      "Iteration1800\n",
      "Iteration1900\n",
      "Iteration2000\n",
      "Iteration2100\n",
      "Iteration2200\n",
      "Iteration2300\n",
      "Iteration2400\n",
      "Iteration2500\n",
      "Iteration2600\n",
      "Iteration2700\n",
      "Iteration2800\n",
      "Iteration2900\n",
      "Iteration3000\n",
      "Iteration3100\n",
      "Iteration3200\n",
      "Iteration3300\n",
      "Iteration3400\n",
      "Iteration3500\n",
      "Iteration3600\n",
      "Iteration3700\n",
      "Iteration3800\n",
      "Iteration3900\n",
      "Iteration4000\n",
      "Iteration4100\n",
      "Iteration4200\n",
      "Iteration4300\n",
      "Iteration4400\n",
      "Iteration4500\n",
      "Iteration4600\n",
      "Iteration4700\n",
      "Iteration4800\n",
      "Iteration4900\n",
      "Iteration5000\n",
      "Iteration5100\n",
      "Iteration5200\n",
      "Iteration5300\n",
      "Iteration5400\n",
      "Iteration5500\n",
      "Iteration5600\n",
      "Iteration5700\n",
      "Iteration5800\n",
      "Iteration5900\n",
      "Iteration6000\n",
      "Iteration6100\n",
      "Iteration6200\n",
      "Iteration6300\n",
      "Iteration6400\n",
      "Iteration6500\n",
      "Iteration6600\n",
      "Iteration6700\n",
      "Iteration6800\n",
      "Iteration6900\n",
      "Iteration7000\n",
      "Iteration7100\n",
      "Iteration7200\n",
      "Iteration7300\n",
      "Iteration7400\n",
      "Iteration7500\n",
      "Iteration7600\n",
      "Iteration7700\n",
      "Iteration7800\n",
      "Iteration7900\n",
      "Iteration8000\n",
      "Iteration8100\n",
      "Iteration8200\n",
      "Iteration8300\n",
      "Iteration8400\n",
      "Iteration8500\n",
      "Iteration8600\n",
      "Iteration8700\n",
      "Iteration8800\n",
      "Iteration8900\n",
      "Iteration9000\n",
      "Iteration9100\n",
      "Iteration9200\n",
      "Iteration9300\n",
      "Iteration9400\n",
      "Iteration9500\n",
      "Iteration9600\n",
      "Iteration9700\n",
      "Iteration9800\n",
      "Iteration9900\n",
      "Iteration10000\n",
      "Iteration10100\n",
      "Iteration10200\n",
      "Iteration10300\n",
      "Iteration10400\n",
      "Iteration10500\n",
      "Iteration10600\n",
      "Iteration10700\n",
      "Iteration10800\n",
      "Iteration10900\n",
      "Iteration11000\n",
      "Iteration11100\n",
      "Iteration11200\n",
      "Iteration11300\n",
      "Iteration11400\n",
      "Iteration11500\n",
      "Iteration11600\n",
      "Iteration11700\n",
      "Iteration11800\n",
      "Iteration11900\n",
      "Iteration12000\n",
      "Iteration12100\n",
      "Iteration12200\n",
      "Iteration12300\n",
      "Iteration12400\n",
      "Iteration12500\n",
      "Iteration12600\n",
      "Iteration12700\n",
      "Iteration12800\n",
      "Iteration12900\n",
      "Iteration13000\n",
      "Iteration13100\n",
      "Iteration13200\n",
      "Iteration13300\n",
      "Iteration13400\n",
      "Iteration13500\n",
      "Iteration13600\n",
      "Iteration13700\n",
      "Iteration13800\n",
      "Iteration13900\n",
      "Iteration14000\n",
      "Iteration14100\n",
      "Iteration14200\n",
      "Iteration14300\n",
      "Iteration14400\n",
      "Iteration14500\n",
      "Iteration14600\n",
      "Iteration14700\n",
      "Iteration14800\n",
      "Iteration14900\n",
      "Iteration15000\n",
      "Iteration15100\n",
      "Iteration15200\n",
      "Iteration15300\n",
      "Iteration15400\n",
      "Iteration15500\n",
      "Iteration15600\n",
      "Iteration15700\n",
      "Iteration15800\n",
      "Iteration15900\n",
      "Iteration16000\n",
      "Iteration16100\n",
      "Iteration16200\n",
      "Iteration16300\n",
      "Iteration16400\n",
      "Iteration16500\n",
      "Iteration16600\n",
      "Iteration16700\n",
      "Iteration16800\n",
      "Iteration16900\n",
      "Iteration17000\n",
      "Iteration17100\n",
      "Iteration17200\n",
      "Iteration17300\n",
      "Iteration17400\n",
      "Iteration17500\n",
      "Iteration17600\n",
      "Iteration17700\n",
      "Iteration17800\n",
      "Iteration17900\n",
      "Iteration18000\n",
      "Iteration18100\n",
      "Iteration18200\n",
      "Iteration18300\n",
      "Iteration18400\n",
      "Iteration18500\n",
      "Iteration18600\n",
      "Iteration18700\n",
      "Iteration18800\n",
      "Iteration18900\n",
      "Iteration19000\n",
      "Iteration19100\n",
      "Iteration19200\n",
      "Iteration19300\n",
      "Iteration19400\n",
      "Iteration19500\n",
      "Iteration19600\n",
      "Iteration19700\n",
      "Iteration19800\n",
      "Iteration19900\n",
      "Iteration20000\n",
      "Iteration20100\n",
      "Iteration20200\n",
      "Iteration20300\n",
      "Iteration20400\n",
      "Iteration20500\n",
      "Iteration20600\n",
      "Iteration20700\n",
      "Iteration20800\n",
      "Iteration20900\n",
      "Iteration21000\n",
      "Iteration21100\n",
      "Iteration21200\n",
      "Iteration21300\n",
      "Iteration21400\n",
      "Iteration21500\n",
      "Iteration21600\n",
      "Iteration21700\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyfmi import load_fmu\n",
    "#import numpy as np\n",
    "#os.chdir(r'C:\\Users\\Harold\\Desktop\\test_fmu')\n",
    "#model = load_fmu(\"CELLS_v1.fmu\",log_level=4)\n",
    "#\n",
    "#\n",
    "#simtime = 0\n",
    "#days = 151 \n",
    "#hours = 24  \n",
    "#minutes = 6\n",
    "#seconds = 60\n",
    "#ep_timestep = 6\n",
    "#\n",
    "#numsteps = days * hours * ep_timestep       # total number of simulation steps during the simulationx\n",
    "#timestop = days * hours * minutes * seconds # total time length of our simulation\n",
    "#secondstep = timestop / numsteps  # length of a single step in seconds\n",
    "#simtime = 0                                # keeps track of current time in the simulation\n",
    "#\n",
    "#opts = model.simulate_options()  # Get the default options\n",
    "#opts['ncp'] = numsteps  # Specifies the number of timesteps\n",
    "#opts['initialize'] = False\n",
    "#\n",
    "#\n",
    "##model.initialize(simtime, timestop)\n",
    "#model.initialize(start_time = simtime, stop_time_defined = True, stop_time = 86400)\n",
    "#curr_obs = np.array(list(model.get(['Tair', 'RH', 'Tmrt', 'Tout', 'Qheat', 'Occ'])))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e78a7ef29a5e3028f948eff69c34ba1d8ebd35a887497a02775c6aab840f6bc2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
