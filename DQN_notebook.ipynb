{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, List, Tuple\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import gym\n",
    "import envs\n",
    "from datetime import datetime\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "from pyfmi import load_fmu\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.offline as pyo\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"A simple numpy replay buffer.\"\"\"\n",
    "\n",
    "    def __init__(self, obs_dim: int, size: int, batch_size: int = 32):\n",
    "        self.obs_dim = obs_dim\n",
    "        self.obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "        self.next_obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "        self.acts_buf = np.zeros([size], dtype=np.float32)\n",
    "        self.rews_buf = np.zeros([size], dtype=np.float32)\n",
    "        self.done_buf = np.zeros(size, dtype=np.float32)\n",
    "        self.max_size, self.batch_size = size, batch_size\n",
    "        self.ptr, self.size, = 0, 0\n",
    "\n",
    "    def store(\n",
    "        self,\n",
    "        obs: np.ndarray,\n",
    "        act: np.ndarray, \n",
    "        rew: float, \n",
    "        next_obs: np.ndarray, \n",
    "        done: bool,\n",
    "    ):\n",
    "        self.obs_buf[self.ptr] = obs.reshape(self.obs_buf[self.ptr].shape)\n",
    "        self.next_obs_buf[self.ptr] = next_obs.reshape(self.obs_buf[self.ptr].shape)\n",
    "        self.acts_buf[self.ptr] = act\n",
    "        self.rews_buf[self.ptr] = rew\n",
    "        self.done_buf[self.ptr] = done\n",
    "        self.ptr = (self.ptr + 1) % self.max_size\n",
    "        self.size = min(self.size + 1, self.max_size)\n",
    "\n",
    "    def sample_batch(self) -> Dict[str, np.ndarray]:\n",
    "        idxs = np.random.choice(self.size, size=self.batch_size, replace=False)\n",
    "        return dict(obs=self.obs_buf[idxs],\n",
    "                    next_obs=self.next_obs_buf[idxs],\n",
    "                    acts=self.acts_buf[idxs],\n",
    "                    rews=self.rews_buf[idxs],\n",
    "                    done=self.done_buf[idxs])\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, in_dim: int, out_dim: int):\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        super(Network, self).__init__()\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(in_dim, 128), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(128, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward method implementation.\"\"\"\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    \"\"\"DQN Agent interacting with environment.\n",
    "    \n",
    "    Attribute:\n",
    "        env : (Environment) custom Environment to interact with TRNSYS\n",
    "        memory (ReplayBuffer): replay memory to store transitions\n",
    "        batch_size (int): batch size for sampling\n",
    "        epsilon (float): parameter for epsilon greedy policy\n",
    "        epsilon_decay (float): step size to decrease epsilon\n",
    "        max_epsilon (float): max value of epsilon\n",
    "        min_epsilon (float): min value of epsilon\n",
    "        target_update (int): period for target model's hard update\n",
    "        gamma (float): discount factor\n",
    "        dqn (Network): model to train and select actions\n",
    "        dqn_target (Network): target model to update\n",
    "        optimizer (torch.optim): optimizer for training dqn\n",
    "        transition (list): transition information including \n",
    "                           state, action, reward, next_state, done\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        env: gym.Env,\n",
    "        memory_size: int,\n",
    "        batch_size: int,\n",
    "        target_update: int,\n",
    "        epsilon_decay: float,\n",
    "        max_epsilon: float = 1.0,\n",
    "        min_epsilon: float = 0.1,\n",
    "        gamma: float = 0.99,\n",
    "    ):\n",
    "        \"\"\"Initialization.\n",
    "        \n",
    "        Args:\n",
    "            env (gym.Env): custom Environment to interact with TRNSYS\n",
    "            memory_size (int): length of memory\n",
    "            batch_size (int): batch size for sampling\n",
    "            target_update (int): period for target model's hard update\n",
    "            epsilon_decay (float): step size to decrease epsilon\n",
    "            lr (float): learning rate\n",
    "            max_epsilon (float): max value of epsilon\n",
    "            min_epsilon (float): min value of epsilon\n",
    "            gamma (float): discount factor\n",
    "        \"\"\"\n",
    "        ## dimensions for the network\n",
    "        obs_dim = env.observation_dim\n",
    "        action_dim = env.action_dim\n",
    "        \n",
    "        self.env = env\n",
    "        self.memory = ReplayBuffer(obs_dim, memory_size, batch_size)\n",
    "        self.batch_size = batch_size\n",
    "        self.epsilon = max_epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.max_epsilon = max_epsilon\n",
    "        self.min_epsilon = min_epsilon\n",
    "        self.target_update = target_update\n",
    "        self.gamma = gamma\n",
    "        \n",
    "        # device: cpu / gpu\n",
    "        self.device = torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        )\n",
    "\n",
    "\n",
    "        print(self.device)\n",
    "\n",
    "        # networks: dqn, dqn_target\n",
    "        self.dqn = Network(obs_dim, action_dim).to(self.device)\n",
    "        self.dqn_target = Network(obs_dim, action_dim).to(self.device)\n",
    "        self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
    "        self.dqn_target.eval()\n",
    "        \n",
    "        # optimizer\n",
    "        self.optimizer = optim.Adam(self.dqn.parameters())\n",
    "\n",
    "        # transition to store in memory\n",
    "        self.transition = list()\n",
    "        \n",
    "        # mode: train / test\n",
    "        self.is_test = False\n",
    "\n",
    "\n",
    "    def __getattribute__(self, attr):\n",
    "        return object.__getattribute__(self, attr)\n",
    "\n",
    "    def __setattr__(self, attr, value):\n",
    "        object.__setattr__(self, attr, value)\n",
    "\n",
    "        \n",
    "\n",
    "    def select_action(self, state: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Select an action from the input state.\"\"\"\n",
    "        # epsilon greedy policy\n",
    "        if self.epsilon > np.random.random():\n",
    "            selected_action = np.random.choice(self.env.action_dim,1)[0]\n",
    "        else:\n",
    "            selected_action = self.dqn(\n",
    "                torch.FloatTensor(state.T).to(self.device)\n",
    "            ).argmax()\n",
    "            selected_action = selected_action.detach().cpu().numpy()\n",
    "        \n",
    "        if not self.is_test:\n",
    "            self.transition = [state, selected_action]\n",
    "        \n",
    "        return selected_action\n",
    "\n",
    "    def step(self, action: np.ndarray) -> Tuple[np.ndarray, np.float64, bool]:\n",
    "        \"\"\"Take an action and return the response of the env.\"\"\"\n",
    "        next_state, reward, done, info = self.env.step(action)\n",
    "\n",
    "        if not self.is_test:\n",
    "            self.transition += [reward, next_state, done]\n",
    "            self.memory.store(*self.transition)\n",
    "    \n",
    "        return next_state, reward, done, info\n",
    "\n",
    "    def update_model(self) -> torch.Tensor:\n",
    "        \"\"\"Update the model by gradient descent.\"\"\"\n",
    "        samples = self.memory.sample_batch()\n",
    "\n",
    "        loss = self._compute_dqn_loss(samples)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return loss.item()\n",
    "        \n",
    "    def train(self,num_iterations= None, num_episodes= 1):\n",
    "        \"\"\"Train the agent.\"\"\"\n",
    "        self.is_test = False\n",
    "        ## getting current date for logging reasons\n",
    "        date = datetime.now()\n",
    "        temp = list([date.year,date.month,date.day,date.hour,date.minute])\n",
    "        temp = [str(x) for x in temp]\n",
    "        time = \"_\".join(temp)\n",
    "        RESULT_PATH = f\"./results/{str(date.year)}_{str(date.month)}_{str(date.day)}/results_{time}\"\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        for episode_num in range(num_episodes):\n",
    "        \n",
    "            state = self.env.reset()\n",
    "\n",
    "            if episode_num == 0:\n",
    "                os.makedirs(RESULT_PATH,exist_ok=True)\n",
    "\n",
    "            update_cnt = 0\n",
    "            epsilons = []\n",
    "            losses = []\n",
    "            tair = []\n",
    "            actions = []\n",
    "            pmv = []\n",
    "            qheat = []\n",
    "            rewards = []\n",
    "            occ = []\n",
    "\n",
    "            if num_iterations is None:\n",
    "                num_iterations=env.numsteps\n",
    "\n",
    "\n",
    "            for i in range(num_iterations):\n",
    "\n",
    "                action = self.select_action(state)\n",
    "                next_state, reward, done,info = self.step(action)\n",
    "\n",
    "                if i % 100 == 0:\n",
    "                    print(f\"Iteration{i}\")\n",
    "\n",
    "                ## keeping track of the value we've seen\n",
    "                rewards.append(reward)\n",
    "                actions.append(env.action_to_temp[action])\n",
    "                pmv.append(info['pmv'][0])\n",
    "                d = env.observation_to_dict(next_state)\n",
    "                tair.append(d[\"Tair\"][0])\n",
    "                qheat.append(d[\"Qheat\"][0])\n",
    "                occ.append(d[\"Occ\"][0])\n",
    "\n",
    "\n",
    "\n",
    "                state = next_state\n",
    "\n",
    "                # if episode ends\n",
    "                #if done:\n",
    "                #    state = self.env.reset()\n",
    "\n",
    "                # if training is ready\n",
    "                if len(self.memory) >= self.batch_size:\n",
    "                    loss = self.update_model()\n",
    "                    losses.append(loss)\n",
    "                    update_cnt += 1\n",
    "\n",
    "                    # linearly decrease epsilon\n",
    "                    self.epsilon = max(\n",
    "                        self.min_epsilon, self.epsilon - (\n",
    "                            self.max_epsilon - self.min_epsilon\n",
    "                        ) * self.epsilon_decay\n",
    "                    )\n",
    "                    epsilons.append(self.epsilon)\n",
    "\n",
    "                    # if hard update is needed\n",
    "                    if update_cnt % self.target_update == 0:\n",
    "                        self._target_hard_update()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            plot_filename=f\"{RESULT_PATH}/results_{episode_num+1}.html\"\n",
    "            self._plot(epsilons,losses,tair,actions,pmv,qheat,rewards,occ,plot_filename = plot_filename, title=f\"Episode Number {episode_num+1}\")\n",
    "\n",
    "            self.plot_pmv_percentages(pmv=np.array(pmv),savepath=RESULT_PATH, title = f\"PMV_Categories_{episode_num+1}\" )\n",
    "\n",
    "            ## padding losses and epsilons so that they fit into dataframe\n",
    "            len_difference = len(tair) - len(losses)\n",
    "            pad_losses = [0 for i in range(len_difference)]\n",
    "            pad_epsilon = [epsilons[0] for i in range(len_difference)]\n",
    "\n",
    "            losses = pad_losses + losses\n",
    "            epsilons = pad_epsilon + epsilons\n",
    "\n",
    "            data = pd.DataFrame({\"loss\": losses, \"epsilon\":epsilons, \"tair\":tair, \"action\":actions,\n",
    "            \"pmv\":pmv, \"qheat\":qheat,\"reward\":rewards, \"occ\":occ})\n",
    "\n",
    "            data.to_csv(f\"{RESULT_PATH}/experiments_results_{episode_num+1}.csv\")\n",
    "\n",
    "            ## saving parameters of environment\n",
    "\n",
    "            f = open(f\"{RESULT_PATH}/env_params_{time}.json\",\"w\")\n",
    "            f.write(json.dumps(env.log_dict(),indent=True))\n",
    "            f.close()\n",
    "\n",
    "            self.save(directory=RESULT_PATH,filename=\"torch\")\n",
    "                \n",
    "\n",
    "        #self.env.close()\n",
    "\n",
    "\n",
    "    def _plot(\n",
    "        self, \n",
    "        epsilons: List[float],\n",
    "        losses : List[float],\n",
    "        tair: List[float],\n",
    "        actions: List[float],\n",
    "        pmv : List[float],\n",
    "        qheat: List[float],\n",
    "        rewards: List[float],\n",
    "        occ : List[float],\n",
    "        plot_filename:str,\n",
    "        title:str\n",
    "       ):\n",
    "\n",
    "        epsilons = np.array(epsilons)\n",
    "        losses = np.array(losses)\n",
    "        tair= np.array(tair)\n",
    "        actions = np.array(actions)\n",
    "        pmv = np.array(pmv)\n",
    "        qheat = np.array(qheat)\n",
    "        rewards = np.array(rewards)\n",
    "        occ = np.array(occ)\n",
    "\n",
    "\n",
    "        # Plotting the summary of simulation\n",
    "        fig = make_subplots(rows=8, cols=1, shared_xaxes=True, vertical_spacing=0.02,\n",
    "                            specs=[[{\"secondary_y\": False}], [{\"secondary_y\": False}], [{\"secondary_y\": False}],\n",
    "                                   [{\"secondary_y\": True}], [{\"secondary_y\": True}], [{\"secondary_y\": False}],\n",
    "                                   [{\"secondary_y\": True}], [{\"secondary_y\": True}]])\n",
    "        \n",
    "        iterations = len(tair)\n",
    "        t = np.linspace(0.0, iterations -1, iterations)\n",
    "        # Add traces\n",
    "        fig.add_trace(go.Scatter(name='Tair(state)', x=t, y=tair.flatten(), mode='lines', line=dict(width=1, color='cyan')),\n",
    "                      row=1, col=1)\n",
    "        #fig.add_trace(go.Scatter(name='Tair_avg', x=t, y=pd.Series(tair.flatten()).rolling(window=60).mean(), mode='lines',\n",
    "        #              line=dict(width=2, color='blue')), row=1, col=1)\n",
    "\n",
    "        fig.add_trace(go.Scatter(name='Tset(action)', x=t, y=actions.flatten(), mode='lines', line=dict(width=1, color='fuchsia')),\n",
    "                      row=2, col=1)\n",
    "        fig.add_trace(go.Scatter(name='Tset_avg', x=t, y=pd.Series(actions.flatten()).rolling(window=24).mean(), mode='lines',\n",
    "                      line=dict(width=2, color='purple')), row=2, col=1)\n",
    "\n",
    "        fig.add_trace(go.Scatter(name='Pmv', x=t, y=pmv.flatten(), mode='lines', line=dict(width=1, color='gold')),\n",
    "                      row=3, col=1)\n",
    "        #fig.add_trace(go.Scatter(name='Pmv_avg', x=t, y=pd.Series(pmv.flatten()).rolling(window=60).mean(), mode='lines',\n",
    "        #              line=dict(width=2, color='darkorange')), row=3, col=1)\n",
    "\n",
    "        fig.add_trace(go.Scatter(name='Heating', x=t, y=qheat.flatten(), mode='lines', line=dict(width=1, color='red')),\n",
    "                      row=4, col=1, secondary_y=False)\n",
    "        fig.add_trace(go.Scatter(name='Heating_cumulative', x=t, y=np.cumsum(qheat.flatten()), mode='lines',\n",
    "                      line=dict(width=2, color='darkred')), row=4, col=1, secondary_y=True)\n",
    "\n",
    "        fig.add_trace(go.Scatter(name='Reward', x=t, y=rewards.flatten(), mode='lines', line=dict(width=1, color='lime')),\n",
    "                      row=5, col=1, secondary_y=False)\n",
    "        fig.add_trace(go.Scatter(name='Reward_cum', x=t, y=np.cumsum(rewards.flatten()), mode='lines',\n",
    "                      line=dict(width=2, color='darkgreen')), row=5, col=1, secondary_y=True)\n",
    "\n",
    "        fig.add_trace(go.Scatter(name='Occupancy', x=t, y=occ.flatten(), mode='lines',\n",
    "                      line=dict(width=1, color='black')), row=6, col=1)\n",
    "        ## training part\n",
    "\n",
    "        fig.add_trace(go.Scatter(name='Epsilons', x=t, y=epsilons.flatten(), mode='lines',\n",
    "                      line=dict(width=1, color='blue')), row=7, col=1)\n",
    "        fig.add_trace(go.Scatter(name='Training Loss', x=t, y=losses.flatten(), mode='lines',\n",
    "                      line=dict(width=1, color='darkblue')), row=8, col=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Set x-axis title\n",
    "        fig.update_xaxes(title_text=\"Timestep (-)\", row=6, col=1)\n",
    "        # Set y-axes titles\n",
    "        fig.update_yaxes(title_text=\"<b>Tair</b> (°C)\", range=[10, 24], row=1, col=1)\n",
    "        fig.update_yaxes(title_text=\"<b>Tset</b> (°C)\", range=[14, 22], row=2, col=1)\n",
    "        fig.update_yaxes(title_text=\"<b>PMV</b> (-)\", row=3, col=1)\n",
    "        fig.update_yaxes(title_text=\"<b>Heat Power</b> (kJ/hr)\", row=4, col=1, secondary_y=False)\n",
    "        fig.update_yaxes(title_text=\"<b>Heat Energy</b> (kJ)\", row=4, col=1, secondary_y=True)\n",
    "        fig.update_yaxes(title_text=\"<b>Reward</b> (-)\", row=5, col=1, range=[-5, 5], secondary_y=False)\n",
    "        fig.update_yaxes(title_text=\"<b>Tot Reward</b> (-)\", row=5, col=1, secondary_y=True)\n",
    "        fig.update_yaxes(title_text=\"<b>Occ</b> (-)\", row=6, col=1)\n",
    "        fig.update_yaxes(title_text=\"<b>Epsilon</b> (-)\", row=7, col=1)\n",
    "        fig.update_yaxes(title_text=\"<b>Loss</b> (-)\", row=8, col=1)\n",
    "\n",
    "\n",
    "        fig.update_xaxes(nticks=50)\n",
    "        fig.update_layout(template='plotly_white', font=dict(family=\"Courier New, monospace\", size=10),\n",
    "                          legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1, xanchor=\"right\", x=1))\n",
    "\n",
    "\n",
    "        fig.update_layout(title_text=title)\n",
    "            \n",
    "        pyo.plot(fig, filename=plot_filename)\n",
    "        ## saving as image to\n",
    "\n",
    "        \n",
    "\n",
    "    def plot_pmv_percentages(self, pmv: np.ndarray, savepath:str, title:str):\n",
    "        \n",
    "        temp = pmv\n",
    "        intervals = []\n",
    "        \n",
    "        length = 8\n",
    "        lower= -2\n",
    "        step = 0.5\n",
    "        \n",
    "        ranges = np.zeros(length)\n",
    "        \n",
    "        for i in range(length):\n",
    "        \n",
    "            if i == 0:\n",
    "                ranges[i] = (temp < lower).sum()\n",
    "                interval = f\"[-inf,{lower}]\"\n",
    "                intervals.append(interval)\n",
    "        \n",
    "            elif i == 7:\n",
    "                upper = (i-1)*step + lower\n",
    "                ranges[i] = ( upper<= temp).sum()\n",
    "                interval = f\"[{upper},inf]\"\n",
    "                intervals.append(interval)\n",
    "        \n",
    "            else:\n",
    "                lower_1 = lower + (i-1)*step\n",
    "                upper_1 = lower + (i)*step\n",
    "                ranges[i] = (( lower_1 <= temp) &(temp < upper_1)).sum()\n",
    "                interval = f\"[{lower_1},{upper_1}]\"\n",
    "                intervals.append(interval)\n",
    "        \n",
    "        \n",
    "        ranges = ranges / ranges.sum()\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "        # assign data\n",
    "        data = pd.DataFrame({'intervals':intervals,\n",
    "                             'ranges': ranges\n",
    "                            })\n",
    "        \n",
    "        \n",
    "        # compute percentage of each format\n",
    "        percentage = []\n",
    "        for i in range(data.shape[0]):\n",
    "            pct = data.ranges[i] * 100\n",
    "            percentage.append(round(pct,2))\n",
    "        data['Percentage'] = percentage\n",
    "        \n",
    "    \n",
    "        f,a = plt.subplots(1,1, figsize=(15,7))\n",
    "        colors_list = ['darkred','coral', 'coral', 'seagreen', 'lime', 'seagreen','coral','darkred']\n",
    "    \n",
    "        graph = plt.bar(x= data.intervals,height= data.ranges, color = colors_list)\n",
    "    \n",
    "        plt.xlabel(\"PMV value interval\")\n",
    "        plt.ylabel(\"Percentage of hours in interval\")\n",
    "        plt.title(\"Number of hours the algorithm spent in different PMV intervals\")\n",
    "        \n",
    "        i = 0\n",
    "        for p in graph:\n",
    "            width = p.get_width()\n",
    "            height = p.get_height()\n",
    "            x, y = p.get_xy()\n",
    "            plt.text(x+width/2,\n",
    "                     y+height*1.01,\n",
    "                     str(data.Percentage[i])+'%',\n",
    "                     ha='center',\n",
    "                     weight='bold')\n",
    "            i+=1\n",
    "\n",
    "        plt.savefig(f\"{savepath}/{title}.png\",dpi=400)\n",
    "\n",
    "                \n",
    "\n",
    "    def _compute_dqn_loss(self, samples: Dict[str, np.ndarray]) -> torch.Tensor:\n",
    "        \"\"\"Return dqn loss.\"\"\"\n",
    "        device = self.device  # for shortening the following lines\n",
    "        state = torch.FloatTensor(samples[\"obs\"]).to(device)\n",
    "        next_state = torch.FloatTensor(samples[\"next_obs\"]).to(device)\n",
    "        action = torch.LongTensor(samples[\"acts\"].reshape(-1, 1)).to(device)\n",
    "        reward = torch.FloatTensor(samples[\"rews\"].reshape(-1, 1)).to(device)\n",
    "        done = torch.FloatTensor(samples[\"done\"].reshape(-1, 1)).to(device)\n",
    "\n",
    "        # G_t   = r + gamma * v(s_{t+1})  if state != Terminal\n",
    "        #       = r                       otherwise\n",
    "        curr_q_value = self.dqn(state).gather(1, action)\n",
    "        next_q_value = self.dqn_target(\n",
    "            next_state\n",
    "        ).max(dim=1, keepdim=True)[0].detach()\n",
    "        mask = 1 - done\n",
    "        target = (reward + self.gamma * next_q_value * mask).to(self.device)\n",
    "\n",
    "        # calculate dqn loss\n",
    "        loss = F.smooth_l1_loss(curr_q_value, target)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def _target_hard_update(self):\n",
    "        \"\"\"Hard update: target <- local.\"\"\"\n",
    "        self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
    "\n",
    "\n",
    "    # Making a save method to save a trained model\n",
    "    def save(self, filename, directory):\n",
    "        torch.save(self.dqn.state_dict(), '%s/%s_dqn.pth' % (directory, filename))\n",
    "        torch.save(self.dqn_target.state_dict(), '%s/%s_dqn_target.pth' % (directory, filename))\n",
    "\n",
    "    # Making a load method to load a pre-trained model\n",
    "    def load(self, filename, directory):\n",
    "        self.dqn.load_state_dict(torch.load('%s/%s_dqn.pth' % (directory, filename)))\n",
    "        self.dqn_target.load_state_dict(torch.load('%s/%s_dqn_target.pth' % (directory, filename)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 778\n",
    "\n",
    "\n",
    "def seed_torch(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.backends.cudnn.enabled:\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "np.random.seed(seed)\n",
    "seed_torch(seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set environment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('EnergyPlusEnv-v0')\n",
    "env.seed(seed)\n",
    "\n",
    "env.beta =1 \n",
    "env.alpha = 1\n",
    "env.min_temp = 16\n",
    "env.max_temp = 21\n",
    "env.action_dim =200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('EnergyPlusEnv-v0')\n",
    "env.seed(seed)\n",
    "\n",
    "env.beta =1 \n",
    "env.alpha = 1\n",
    "env.min_temp = 16\n",
    "env.max_temp = 21\n",
    "env.action_dim =200\n",
    "\n",
    "env.modelname = 'CELLS_v1.fmu'\n",
    "env.simulation_path = r'C:\\Users\\Harold\\Desktop\\ENAC-Semester-Project\\DIET_Controller\\custom_gym\\Eplus_simulation'\n",
    "env.param_list = ['Tair', 'RH', 'Tmrt', 'Tout', 'Qheat', 'Occ']\n",
    "\n",
    "env.days = 151,  \n",
    "env.hours = 24,  \n",
    "env.minutes = 60,\n",
    "env.seconds = 60,\n",
    "env.ep_timestep = 6\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "memory_size = 1000\n",
    "batch_size = 32\n",
    "target_update = 100\n",
    "epsilon_decay = 1 / 2000\n",
    "\n",
    "agent = DQNAgent(env,memory_size,batch_size,target_update,epsilon_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration0\n",
      "Iteration100\n",
      "Iteration200\n",
      "Iteration300\n",
      "Iteration400\n",
      "Iteration500\n",
      "Iteration600\n",
      "Iteration700\n",
      "Iteration800\n",
      "Iteration900\n",
      "Iteration1000\n",
      "Iteration1100\n",
      "Iteration1200\n",
      "Iteration1300\n",
      "Iteration1400\n",
      "Iteration1500\n",
      "Iteration1600\n",
      "Iteration1700\n",
      "Iteration1800\n",
      "Iteration1900\n",
      "Iteration2000\n",
      "Iteration2100\n",
      "Iteration2200\n",
      "Iteration2300\n",
      "Iteration2400\n",
      "Iteration2500\n",
      "Iteration2600\n",
      "Iteration2700\n",
      "Iteration2800\n",
      "Iteration2900\n",
      "Iteration3000\n",
      "Iteration3100\n",
      "Iteration3200\n",
      "Iteration3300\n",
      "Iteration3400\n",
      "Iteration3500\n",
      "Iteration3600\n",
      "Iteration3700\n",
      "Iteration3800\n",
      "Iteration3900\n",
      "Iteration4000\n",
      "Iteration4100\n",
      "Iteration4200\n",
      "Iteration4300\n",
      "Iteration4400\n",
      "Iteration4500\n",
      "Iteration4600\n",
      "Iteration4700\n",
      "Iteration4800\n",
      "Iteration4900\n",
      "Iteration5000\n",
      "Iteration5100\n",
      "Iteration5200\n",
      "Iteration5300\n",
      "Iteration5400\n",
      "Iteration5500\n",
      "Iteration5600\n",
      "Iteration5700\n",
      "Iteration5800\n",
      "Iteration5900\n",
      "Iteration6000\n",
      "Iteration6100\n",
      "Iteration6200\n",
      "Iteration6300\n",
      "Iteration6400\n",
      "Iteration6500\n",
      "Iteration6600\n",
      "Iteration6700\n",
      "Iteration6800\n",
      "Iteration6900\n",
      "Iteration7000\n",
      "Iteration7100\n",
      "Iteration7200\n",
      "Iteration7300\n",
      "Iteration7400\n",
      "Iteration7500\n",
      "Iteration7600\n",
      "Iteration7700\n",
      "Iteration7800\n",
      "Iteration7900\n",
      "Iteration8000\n",
      "Iteration8100\n",
      "Iteration8200\n",
      "Iteration8300\n",
      "Iteration8400\n",
      "Iteration8500\n",
      "Iteration8600\n",
      "Iteration8700\n",
      "Iteration8800\n",
      "Iteration8900\n",
      "Iteration9000\n",
      "Iteration9100\n",
      "Iteration9200\n",
      "Iteration9300\n",
      "Iteration9400\n",
      "Iteration9500\n",
      "Iteration9600\n",
      "Iteration9700\n",
      "Iteration9800\n",
      "Iteration9900\n",
      "Iteration10000\n",
      "Iteration10100\n",
      "Iteration10200\n",
      "Iteration10300\n",
      "Iteration10400\n",
      "Iteration10500\n",
      "Iteration10600\n",
      "Iteration10700\n",
      "Iteration10800\n",
      "Iteration10900\n",
      "Iteration11000\n",
      "Iteration11100\n",
      "Iteration11200\n",
      "Iteration11300\n",
      "Iteration11400\n",
      "Iteration11500\n",
      "Iteration11600\n",
      "Iteration11700\n",
      "Iteration11800\n",
      "Iteration11900\n",
      "Iteration12000\n",
      "Iteration12100\n",
      "Iteration12200\n",
      "Iteration12300\n",
      "Iteration12400\n",
      "Iteration12500\n",
      "Iteration12600\n",
      "Iteration12700\n",
      "Iteration12800\n",
      "Iteration12900\n",
      "Iteration13000\n",
      "Iteration13100\n",
      "Iteration13200\n",
      "Iteration13300\n",
      "Iteration13400\n",
      "Iteration13500\n",
      "Iteration13600\n",
      "Iteration13700\n",
      "Iteration13800\n",
      "Iteration13900\n",
      "Iteration14000\n",
      "Iteration14100\n",
      "Iteration14200\n",
      "Iteration14300\n",
      "Iteration14400\n",
      "Iteration14500\n",
      "Iteration14600\n",
      "Iteration14700\n",
      "Iteration14800\n",
      "Iteration14900\n",
      "Iteration15000\n",
      "Iteration15100\n",
      "Iteration15200\n",
      "Iteration15300\n",
      "Iteration15400\n",
      "Iteration15500\n",
      "Iteration15600\n",
      "Iteration15700\n",
      "Iteration15800\n",
      "Iteration15900\n",
      "Iteration16000\n",
      "Iteration16100\n",
      "Iteration16200\n",
      "Iteration16300\n",
      "Iteration16400\n",
      "Iteration16500\n",
      "Iteration16600\n",
      "Iteration16700\n",
      "Iteration16800\n",
      "Iteration16900\n",
      "Iteration17000\n",
      "Iteration17100\n",
      "Iteration17200\n",
      "Iteration17300\n",
      "Iteration17400\n",
      "Iteration17500\n",
      "Iteration17600\n",
      "Iteration17700\n",
      "Iteration17800\n",
      "Iteration17900\n",
      "Iteration18000\n",
      "Iteration18100\n",
      "Iteration18200\n",
      "Iteration18300\n",
      "Iteration18400\n",
      "Iteration18500\n",
      "Iteration18600\n",
      "Iteration18700\n",
      "Iteration18800\n",
      "Iteration18900\n",
      "Iteration19000\n",
      "Iteration19100\n",
      "Iteration19200\n",
      "Iteration19300\n",
      "Iteration19400\n",
      "Iteration19500\n",
      "Iteration19600\n",
      "Iteration19700\n",
      "Iteration19800\n",
      "Iteration19900\n",
      "Iteration20000\n",
      "Iteration20100\n",
      "Iteration20200\n",
      "Iteration20300\n",
      "Iteration20400\n",
      "Iteration20500\n",
      "Iteration20600\n",
      "Iteration20700\n",
      "Iteration20800\n",
      "Iteration20900\n",
      "Iteration21000\n",
      "Iteration21100\n",
      "Iteration21200\n",
      "Iteration21300\n",
      "Iteration21400\n",
      "Iteration21500\n",
      "Iteration21600\n",
      "Iteration21700\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent.train(num_episodes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyfmi import load_fmu\n",
    "#import numpy as np\n",
    "#os.chdir(r'C:\\Users\\Harold\\Desktop\\test_fmu')\n",
    "#model = load_fmu(\"CELLS_v1.fmu\",log_level=4)\n",
    "#\n",
    "#\n",
    "#simtime = 0\n",
    "#days = 151 \n",
    "#hours = 24  \n",
    "#minutes = 6\n",
    "#seconds = 60\n",
    "#ep_timestep = 6\n",
    "#\n",
    "#numsteps = days * hours * ep_timestep       # total number of simulation steps during the simulationx\n",
    "#timestop = days * hours * minutes * seconds # total time length of our simulation\n",
    "#secondstep = timestop / numsteps  # length of a single step in seconds\n",
    "#simtime = 0                                # keeps track of current time in the simulation\n",
    "#\n",
    "#opts = model.simulate_options()  # Get the default options\n",
    "#opts['ncp'] = numsteps  # Specifies the number of timesteps\n",
    "#opts['initialize'] = False\n",
    "#\n",
    "#\n",
    "##model.initialize(simtime, timestop)\n",
    "#model.initialize(start_time = simtime, stop_time_defined = True, stop_time = 86400)\n",
    "#curr_obs = np.array(list(model.get(['Tair', 'RH', 'Tmrt', 'Tout', 'Qheat', 'Occ'])))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e78a7ef29a5e3028f948eff69c34ba1d8ebd35a887497a02775c6aab840f6bc2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
