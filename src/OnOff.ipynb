{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from agent.OnOff_Agent import OnOffAgent\n",
    "from environment.ContinuousEnvironment import ContinuousSimpleEnvironment\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from Performance import all_combinations_list\n",
    "from Performance import search_similar\n",
    "import Performance\n",
    "from logger.SimpleLogger import SimpleLogger\n",
    "\n",
    "results_dict = {}\n",
    "\n",
    "for alpha_value in [0.25,1,4]:\n",
    "    env = ContinuousSimpleEnvironment(param_list=['Tair', 'RH', 'Tmrt', 'Tout', 'Qheat', 'Occ'],\n",
    "    alpha=alpha_value,\n",
    "    beta=1,\n",
    "    min_temp=16,\n",
    "    max_temp=21,\n",
    "    modelname='CELLS_v1.fmu',\n",
    "    simulation_path=r'C:\\Users\\hbenoit\\Desktop\\DIET_Controller\\EnergyPlus_simulations\\simple_simulation',\n",
    "    days=151,\n",
    "    hours=24,\n",
    "    minutes=60,\n",
    "    seconds=60,\n",
    "    ep_timestep=6)\n",
    "\n",
    "\n",
    "    num_episodes = 5\n",
    "\n",
    "    logging_path = r\"C:\\Users\\hbenoit\\Desktop\\DIET_Controller\\logs\\simple_simulation\"\n",
    "\n",
    "    agent = OnOffAgent(env=env)\n",
    "\n",
    "    results_path, summary_df = agent.train(logging_path= logging_path,\n",
    "             num_iterations= None,\n",
    "             num_episodes=num_episodes,\n",
    "             log=True)\n",
    "\n",
    "    results_dict[alpha_value] = Performance.cumulative_reward(summary_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Performance\n",
    "\n",
    "from agent.DDPG_Agent import DDPG_Agent\n",
    "\n",
    "df = Performance.load_summary_df(r\"C:\\\\Users\\\\hbenoit\\\\Desktop\\\\DIET_Controller\\\\logs\\\\simple_simulation\\\\DDPG_Agent\\\\results\\\\2022_6_19\\\\results_2022_6_19_6_41\")\n",
    "\n",
    "\n",
    "Performance.cumulative_reward(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Performance\n",
    "\n",
    "searching_directory = r\"C:\\Users\\hbenoit\\Desktop\\DIET_Controller\\logs\\simple_simulation\\OnOff_Agent\"\n",
    "\n",
    "conditions = { \"alpha\":[\"=\",0.25],\n",
    "    \"beta\":[\"=\",1], \"num_episodes\":[\"=\",10]}\n",
    "\n",
    "best_path_list = Performance.search_paths(\n",
    "searching_directory,\n",
    "conditions=conditions,\n",
    "top_k=1,\n",
    "utility_function=Performance.cumulative_reward,\n",
    "normalized=True)\n",
    "\n",
    "best_path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Performance\n",
    "from logger.SimpleLogger import SimpleLogger\n",
    "\n",
    "\n",
    "for alpha_value in [1]:\n",
    "    env = ContinuousSimpleEnvironment(param_list=['Tair', 'RH', 'Tmrt', 'Tout', 'Qheat', 'Occ'],\n",
    "    alpha=alpha_value,\n",
    "    beta=1,\n",
    "    min_temp=16,\n",
    "    max_temp=21,\n",
    "    modelname='CELLS_v1.fmu',\n",
    "    simulation_path=r'C:\\Users\\hbenoit\\Desktop\\DIET_Controller\\EnergyPlus_simulations\\simple_simulation',\n",
    "    days=151,\n",
    "    hours=24,\n",
    "    minutes=60,\n",
    "    seconds=60,\n",
    "    ep_timestep=6)\n",
    "\n",
    "    parameter = (\"is_step\",[True])\n",
    "\n",
    "    best_agent_path = r\"C:\\Users\\hbenoit\\Desktop\\DIET_Controller\\logs\\simple_simulation\\OnOff_Agent\\results\\2022_6_20\\results_2022_6_20_2_12\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    logging_path = r\"C:\\Users\\hbenoit\\Desktop\\DIET_Controller\\logs\\simple_simulation\"\n",
    "\n",
    "    utility_function = Performance.cumulative_reward\n",
    "    agent = OnOffAgent(env=env)\n",
    "    num_episodes = 1\n",
    "    num_iterations = env.numsteps\n",
    "    agent_name = \"OnOff_Agent\"\n",
    "\n",
    "    results_dict = Performance.across_runs(\n",
    "    agent=agent,\n",
    "    agent_config_path=best_agent_path,\n",
    "    parameter=parameter,\n",
    "    num_episodes=num_episodes,\n",
    "    num_iterations=num_iterations,\n",
    "    utility_function=utility_function,\n",
    "    alpha=0.05,\n",
    "    window=6,\n",
    "    column_names=[\"Tset\",\"Reward\"],\n",
    "    need_load=False)\n",
    "\n",
    "    logger = SimpleLogger(\n",
    "            logging_path=logging_path,\n",
    "            agent_name=\"OnOff_Agent\",\n",
    "            num_episodes=num_episodes,\n",
    "            num_iterations=num_iterations,\n",
    "        )\n",
    "\n",
    "    results_dict[\"alpha\"]= agent.env.alpha\n",
    "    results_dict[\"beta\"]= agent.env.beta\n",
    "\n",
    "    logger.log_performance_pipeline(results_dict,fixed_policy=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4958ec7dcff5f5ebfb92a5bea20aeb391fd8141699bb6c6ea3d3d9a03f500564"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
